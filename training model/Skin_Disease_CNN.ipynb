{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4332,
     "status": "ok",
     "timestamp": 1741339953460,
     "user": {
      "displayName": "Abhinav Kotagiri",
      "userId": "17189717178513361956"
     },
     "user_tz": -330
    },
    "id": "bjHe4d1t5IEZ",
    "outputId": "f32a70c9-7bdd-447f-a4bf-e49128671496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting keras\n",
      "  Using cached keras-3.9.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.3-cp310-cp310-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /Users/jainisaiabhiram/Library/Python/3.10/lib/python/site-packages (from tensorflow) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Using cached protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.10/site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/jainisaiabhiram/Library/Python/3.10/lib/python/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/jainisaiabhiram/Library/Python/3.10/lib/python/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.70.0-cp310-cp310-macosx_12_0_universal2.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.0.2-cp310-cp310-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.13.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Collecting rich (from keras)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras)\n",
      "  Downloading optree-0.14.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jainisaiabhiram/Library/Python/3.10/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.56.0-cp310-cp310-macosx_10_9_universal2.whl.metadata (101 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.8-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.1.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.2-cp310-cp310-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/homebrew/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Downloading charset_normalizer-3.4.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/jainisaiabhiram/Library/Python/3.10/lib/python/site-packages (from rich->keras) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Downloading tensorflow-2.18.0-cp310-cp310-macosx_12_0_arm64.whl (239.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached keras-3.9.0-py3-none-any.whl (1.3 MB)\n",
      "Downloading numpy-2.0.2-cp310-cp310-macosx_14_0_arm64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.1-cp310-cp310-macosx_11_0_arm64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (37.3 MB)\n",
      "Downloading scikit_learn-1.6.1-cp310-cp310-macosx_12_0_arm64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached contourpy-1.3.1-cp310-cp310-macosx_11_0_arm64.whl (253 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached fonttools-4.56.0-cp310-cp310-macosx_10_9_universal2.whl (2.8 MB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.70.0-cp310-cp310-macosx_12_0_universal2.whl (11.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.13.0-cp310-cp310-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached kiwisolver-1.4.8-cp310-cp310-macosx_11_0_arm64.whl (65 kB)\n",
      "Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "Downloading ml_dtypes-0.4.1-cp310-cp310-macosx_10_9_universal2.whl (397 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached pillow-11.1.0-cp310-cp310-macosx_11_0_arm64.whl (3.1 MB)\n",
      "Using cached protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached scipy-1.15.2-cp310-cp310-macosx_14_0_arm64.whl (22.4 MB)\n",
      "Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-macosx_12_0_arm64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Downloading wrapt-1.17.2-cp310-cp310-macosx_11_0_arm64.whl (38 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.1-cp310-cp310-macosx_11_0_arm64.whl (327 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp310-cp310-macosx_10_9_universal2.whl (198 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp310-cp310-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pytz, namex, libclang, flatbuffers, wrapt, urllib3, tzdata, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, pyparsing, protobuf, pillow, optree, opt-einsum, numpy, mdurl, MarkupSafe, markdown, kiwisolver, joblib, idna, grpcio, google-pasta, gast, fonttools, cycler, charset-normalizer, certifi, astunparse, absl-py, werkzeug, scipy, requests, pandas, opencv-python, ml-dtypes, markdown-it-py, h5py, contourpy, tensorboard, scikit-learn, rich, matplotlib, keras, tensorflow\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.1.0 astunparse-1.6.3 certifi-2025.1.31 charset-normalizer-3.4.1 contourpy-1.3.1 cycler-0.12.1 flatbuffers-25.2.10 fonttools-4.56.0 gast-0.6.0 google-pasta-0.2.0 grpcio-1.70.0 h5py-3.13.0 idna-3.10 joblib-1.4.2 keras-3.9.0 kiwisolver-1.4.8 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 matplotlib-3.10.1 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opencv-python-4.11.0.86 opt-einsum-3.4.0 optree-0.14.1 pandas-2.2.3 pillow-11.1.0 protobuf-5.29.3 pyparsing-3.2.1 pytz-2025.1 requests-2.32.3 rich-13.9.4 scikit-learn-1.6.1 scipy-1.15.2 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 threadpoolctl-3.5.0 tzdata-2025.1 urllib3-2.3.0 werkzeug-3.1.3 wrapt-1.17.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow keras numpy pandas matplotlib opencv-python scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4656,
     "status": "ok",
     "timestamp": 1741339962060,
     "user": {
      "displayName": "Abhinav Kotagiri",
      "userId": "17189717178513361956"
     },
     "user_tz": -330
    },
    "id": "TJpsP7P7_mfh"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1741340002621,
     "user": {
      "displayName": "Abhinav Kotagiri",
      "userId": "17189717178513361956"
     },
     "user_tz": -330
    },
    "id": "iMZAPH6-N-gz"
   },
   "outputs": [],
   "source": [
    "dataset_path = \"/dataset/Train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 639869,
     "status": "ok",
     "timestamp": 1741342761900,
     "user": {
      "displayName": "Abhinav Kotagiri",
      "userId": "17189717178513361956"
     },
     "user_tz": -330
    },
    "id": "F0Dt4sAZOKm-",
    "outputId": "a63d0abe-6f12-430c-fb79-a0955b99f982"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1795 images belonging to 9 classes.\n",
      "Found 444 images belonging to 9 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1542s\u001b[0m 27s/step - accuracy: 0.2152 - loss: 2.1599 - val_accuracy: 0.3806 - val_loss: 1.6519\n",
      "Epoch 2/20\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 920ms/step - accuracy: 0.3774 - loss: 1.6858 - val_accuracy: 0.4077 - val_loss: 1.6767\n",
      "Epoch 3/20\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 927ms/step - accuracy: 0.3990 - loss: 1.5999 - val_accuracy: 0.4459 - val_loss: 1.5878\n",
      "Epoch 4/20\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 944ms/step - accuracy: 0.4622 - loss: 1.4837 - val_accuracy: 0.4527 - val_loss: 1.5336\n",
      "Epoch 5/20\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 897ms/step - accuracy: 0.4762 - loss: 1.4588 - val_accuracy: 0.4685 - val_loss: 1.5661\n",
      "Epoch 6/20\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 890ms/step - accuracy: 0.5035 - loss: 1.4124 - val_accuracy: 0.4730 - val_loss: 1.5737\n",
      "Epoch 7/20\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 882ms/step - accuracy: 0.5048 - loss: 1.3990 - val_accuracy: 0.4730 - val_loss: 1.5684\n",
      "Epoch 8/20\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 902ms/step - accuracy: 0.4941 - loss: 1.4022 - val_accuracy: 0.4977 - val_loss: 1.6375\n",
      "Epoch 9/20\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 928ms/step - accuracy: 0.5219 - loss: 1.3099 - val_accuracy: 0.5135 - val_loss: 1.5228\n",
      "Epoch 10/20\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - accuracy: 0.5432 - loss: 1.2911 - val_accuracy: 0.5068 - val_loss: 1.5656\n",
      "Epoch 11/20\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 885ms/step - accuracy: 0.5347 - loss: 1.2541 - val_accuracy: 0.4797 - val_loss: 1.4433\n",
      "Epoch 12/20\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 900ms/step - accuracy: 0.5623 - loss: 1.2239 - val_accuracy: 0.5000 - val_loss: 1.5288\n",
      "Epoch 13/20\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 937ms/step - accuracy: 0.5589 - loss: 1.2194 - val_accuracy: 0.4910 - val_loss: 1.5954\n",
      "Epoch 14/20\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 917ms/step - accuracy: 0.5656 - loss: 1.2201 - val_accuracy: 0.5135 - val_loss: 1.4609\n",
      "Epoch 15/20\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 928ms/step - accuracy: 0.6035 - loss: 1.1512 - val_accuracy: 0.5045 - val_loss: 1.5060\n",
      "Epoch 16/20\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 916ms/step - accuracy: 0.5759 - loss: 1.2079 - val_accuracy: 0.4685 - val_loss: 1.6826\n",
      "Epoch 17/20\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 919ms/step - accuracy: 0.6036 - loss: 1.1456 - val_accuracy: 0.4865 - val_loss: 1.7146\n",
      "Epoch 18/20\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 923ms/step - accuracy: 0.5847 - loss: 1.1624 - val_accuracy: 0.5225 - val_loss: 1.5882\n",
      "Epoch 19/20\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 900ms/step - accuracy: 0.5861 - loss: 1.0996 - val_accuracy: 0.5270 - val_loss: 1.5506\n",
      "Epoch 20/20\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 887ms/step - accuracy: 0.6072 - loss: 1.0781 - val_accuracy: 0.4865 - val_loss: 1.6265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete. Saved as skin_cancer_model.h5 in Google Drive.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224  # MobileNetV2 input size\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 9  # Number of skin cancer classes\n",
    "\n",
    "# Data Augmentation & Preprocessing\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "val_data = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Load Pre-trained MobileNetV2\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# Freeze base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Custom Classification Head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "# Create Model\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the Model\n",
    "EPOCHS = 20\n",
    "model.fit(train_data, validation_data=val_data, epochs=EPOCHS)\n",
    "\n",
    "# Save Model in Google Drive for Web Deployment\n",
    "model.save(\"/skin_cancer_model.h5\")\n",
    "\n",
    "print(\"Model training complete. Saved as skin_cancer_model.h5 in Google Drive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 707,
     "status": "ok",
     "timestamp": 1741343375634,
     "user": {
      "displayName": "Abhinav Kotagiri",
      "userId": "17189717178513361956"
     },
     "user_tz": -330
    },
    "id": "RIJCGG_chNPG",
    "outputId": "18d8967a-8693-401e-ede2-4b3e411ad996"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Predicted Class Index: 4\n",
      "Confidence Score: 0.9451\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load an image\n",
    "img_path = \"/dataset/Test/nevus/ISIC_0000003.jpg\"  # Change this path\n",
    "img = image.load_img(img_path, target_size=(224, 224))  # Resize to model's input size\n",
    "\n",
    "# Convert image to array\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "img_array = img_array / 255.0  # Normalize (if your training data is normalized)\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class = np.argmax(predictions, axis=1)  # Get the class with highest probability\n",
    "\n",
    "# Print results\n",
    "print(f\"Predicted Class Index: {predicted_class[0]}\")\n",
    "print(f\"Confidence Score: {np.max(predictions):.4f}\")\n",
    "\n",
    "### Try with ISIC__0000013 image from melanoma\n",
    "### Try with ISIC_0000003 image from nevus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1741343113780,
     "user": {
      "displayName": "Abhinav Kotagiri",
      "userId": "17189717178513361956"
     },
     "user_tz": -330
    },
    "id": "LS3WFAIRIzI_",
    "outputId": "a3466789-a8e2-4e6c-a7e8-a9d8598b4be6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'actinic keratosis': 0, 'basal cell carcinoma': 1, 'dermatofibroma': 2, 'melanoma': 3, 'nevus': 4, 'pigmented benign keratosis': 5, 'seborrheic keratosis': 6, 'squamous cell carcinoma': 7, 'vascular lesion': 8}\n"
     ]
    }
   ],
   "source": [
    "class_indices = train_data.class_indices  # Dictionary mapping class names to indices\n",
    "print(class_indices)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPHQeY3zvailYIxNxFj9ula",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
